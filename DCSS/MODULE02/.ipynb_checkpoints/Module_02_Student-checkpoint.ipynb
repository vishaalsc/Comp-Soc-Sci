{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><font color=\"gray\">INTEG 440/640, SOC 440/719</font><br>\n",
    "<font color=\"#49699E\"><strong>MODULE 2</strong> PROBLEM SETS</font>\n",
    "\n",
    "# <font color=\"#49699E\" size=40>Python Programming</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What You Need to Know Before You Start\n",
    "\n",
    "This module notebook is **optional** and **ungraded**. If you are new to Python programming you should do your best to complete these exercises and problems, otherwise you may skip it. Although there will be some differences week to week, most module notebook assignments will look a lot like this one. So if you are curious about what future module notebook assignments will look like, you should also complete this one.\n",
    "\n",
    "You can consult any resources you want when completing these exercises and problems. Just as it is in the \"real world:\" *if you can't figure out how to do something, look it up*. My recommendation is that you check the relevant parts of the assigned reading or search for inspiration on [https://stackoverflow.com](https://stackoverflow.com). You are also free to give and give help from your fellow students. Collaboration is fine!\n",
    "\n",
    "Here are a few things to note about this problem notebook, and those you will receive in future weeks:\n",
    "\n",
    "- Each problem set contains 4 questions. (In this case all four are from the same assigned reading. In future weeks, you will normally see 2 problem sets per assigned reading.)\n",
    "    - **For students in INTEG 440 / SOC 440** \n",
    "        - each problem set is worth 2 points\n",
    "        - each problem within the problem set is worth .5 points\n",
    "    - **For students in INTEG 640 / SOC 719** \n",
    "        - each problem set is worth 1 point\n",
    "        - each problem within the problem set is worth .25 points\n",
    "- For the vast majority of problems in this course, there will be no partial credit. Either you get the points or you don't. We will provide brief but constructive feedback when you don't get the points. This will not be an issue because every problem contained in a problem set is a small well-defined chunk that you can get right or wrong. In cases where that is not true (e.g. an open ended response to a question) we will give partial credit for responses.\n",
    "- Prompts for each problem are provided in the blue cells.\n",
    "\n",
    "Finally, remember that you do not need to \"master\" this content before moving on to other course materials, as what is introduced here is reinforced throughout the rest of the course. You will have plenty of time to practice and cement your new knowledge and skills. However, this assignment may identify content that you do not understand very well. If you notice that is the case, my recommendation is that you revisit the relevant parts of the assigned reading to improve your understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "The cell below contains partially complete code to read a text file into memory. Replace each `___` in the code block to successfully read in the file and print the contents to screen.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Afghanistan', 'Albania', 'Argentina', 'Australia', 'Bangladesh', 'Benin', 'Bhutan', 'Bolivia', 'Botswana', 'Brazil', 'Burkina Faso', 'Burma/Myanmar', 'Burundi', 'Cambodia', 'Canada', 'Cape Verde', 'Central African Republic', 'Chile', 'Colombia', 'Costa Rica', 'Ecuador', 'Egypt', 'El Salvador', 'Ethiopia', 'France', 'Germany', 'Ghana', 'Guatemala', 'Guinea', 'Haiti', 'Honduras', 'India', 'Indonesia', 'Ivory Coast', 'Japan', 'Kenya', 'Kosovo', 'Lebanon', 'Mali', 'Mauritania', 'Mexico', 'Mozambique', 'Nepal', 'Nicaragua', 'Niger', 'Nigeria', 'North Korea', 'Pakistan', 'Peru', 'Philippines', 'Poland', 'Portugal', 'Russia', 'Senegal', 'South Africa', 'South Korea', 'South Sudan', 'Sudan', 'Suriname', 'Sweden', 'Switzerland', 'Taiwan', 'Tanzania', 'Thailand', 'Timor-Leste', 'Uganda', 'United States of America', 'Venezuela', 'Vietnam', 'Yemen', 'Zambia', 'Zimbabwe']\n"
     ]
    }
   ],
   "source": [
    "with open('data/countries.txt', 'r', encoding='utf-8') as file:\n",
    "    countries = [country.strip('\\n') for country in file]\n",
    "\n",
    "print(countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "The cell below iterates over each country name in our list using a for loop and appends an all caps version of the country name to a new list. Complete the code cell below to rewrite the for loop using list comprehension and then confirm that the two lists are identical.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper_fr = []  # an empty list to contain the results of our for loop\n",
    "for country in countries:\n",
    "    upper_fr.append(country.upper())\n",
    "\n",
    "upper_lc = [country.upper() for country in countries]\n",
    "\n",
    "# confirm they are the same\n",
    "upper_fr == upper_lc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "The cell below iterates over the list of countries and creates a new list containing the number of characters in each country name. Complete the code to translate this list comprehension into a for loop and confirm that the results are identical.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_lc = [len(c) for c in countries]  # list comprehension\n",
    "\n",
    "# for loop\n",
    "len_fr = []\n",
    "for country in countries:\n",
    "    len_fr.append(len(country))\n",
    "\n",
    "len_lc == len_fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "The cell below reads the content of a second text file containing the abbreviated names for each of the countries in the initial list. It then uses the <strong>zip()</strong> function to associate the information in both lists based on index positions, and adds the information to a dictionary where the key is the abbreviated name and the value is the full name. Complete the code cell. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AFG': 'Afghanistan',\n",
       " 'ALB': 'Albania',\n",
       " 'ARG': 'Argentina',\n",
       " 'AUS': 'Australia',\n",
       " 'BGD': 'Bangladesh',\n",
       " 'BEN': 'Benin',\n",
       " 'BTN': 'Bhutan',\n",
       " 'BOL': 'Bolivia',\n",
       " 'BWA': 'Botswana',\n",
       " 'BRA': 'Brazil',\n",
       " 'BFA': 'Burkina Faso',\n",
       " 'MMR': 'Burma/Myanmar',\n",
       " 'BDI': 'Burundi',\n",
       " 'KHM': 'Cambodia',\n",
       " 'CAN': 'Canada',\n",
       " 'CPV': 'Cape Verde',\n",
       " 'CAF': 'Central African Republic',\n",
       " 'CHL': 'Chile',\n",
       " 'COL': 'Colombia',\n",
       " 'CRI': 'Costa Rica',\n",
       " 'ECU': 'Ecuador',\n",
       " 'EGY': 'Egypt',\n",
       " 'SLV': 'El Salvador',\n",
       " 'ETH': 'Ethiopia',\n",
       " 'FRA': 'France',\n",
       " 'DEU': 'Germany',\n",
       " 'GHA': 'Ghana',\n",
       " 'GTM': 'Guatemala',\n",
       " 'GIN': 'Guinea',\n",
       " 'HTI': 'Haiti',\n",
       " 'HND': 'Honduras',\n",
       " 'IND': 'India',\n",
       " 'IDN': 'Indonesia',\n",
       " 'CIV': 'Ivory Coast',\n",
       " 'JPN': 'Japan',\n",
       " 'KEN': 'Kenya',\n",
       " 'XKX': 'Kosovo',\n",
       " 'LBN': 'Lebanon',\n",
       " 'MLI': 'Mali',\n",
       " 'MRT': 'Mauritania',\n",
       " 'MEX': 'Mexico',\n",
       " 'MOZ': 'Mozambique',\n",
       " 'NPL': 'Nepal',\n",
       " 'NIC': 'Nicaragua',\n",
       " 'NER': 'Niger',\n",
       " 'NGA': 'Nigeria',\n",
       " 'PRK': 'North Korea',\n",
       " 'PAK': 'Pakistan',\n",
       " 'PER': 'Peru',\n",
       " 'PHL': 'Philippines',\n",
       " 'POL': 'Poland',\n",
       " 'PRT': 'Portugal',\n",
       " 'RUS': 'Russia',\n",
       " 'SEN': 'Senegal',\n",
       " 'ZAF': 'South Africa',\n",
       " 'KOR': 'South Korea',\n",
       " 'SSD': 'South Sudan',\n",
       " 'SDN': 'Sudan',\n",
       " 'SUR': 'Suriname',\n",
       " 'SWE': 'Sweden',\n",
       " 'CHE': 'Switzerland',\n",
       " 'TWN': 'Taiwan',\n",
       " 'TZA': 'Tanzania',\n",
       " 'THA': 'Thailand',\n",
       " 'TLS': 'Timor-Leste',\n",
       " 'UGA': 'Uganda',\n",
       " 'USA': 'United States of America',\n",
       " 'VEN': 'Venezuela',\n",
       " 'VNM': 'Vietnam',\n",
       " 'YEM': 'Yemen',\n",
       " 'ZMB': 'Zambia',\n",
       " 'ZWE': 'Zimbabwe'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/cids.txt', 'r', encoding='utf-8') as f:\n",
    "    cids = [line.strip('\\n') for line in f]\n",
    "    \n",
    "names_and_ids = {}    \n",
    "    \n",
    "for c in zip(cids, countries):\n",
    "    names_and_ids[c[0]] = c[1]\n",
    "\n",
    "names_and_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 2\n",
    "\n",
    "The data used in this problem set comes from the [Varieties of Democracy](https://www.v-dem.net/en/about/) project (V-DEM), which is a massive global project to measure democracy and autocracy around the world, and over time. We will introduce this dataset more fully in Module 3 when we introduce packages for working with structured data. For the moment, we will just work with a few variables without being overly concerned with where they came from or how they were developed. **All of the V-DEM data used here is from 2019.**\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "The code below reads a Python dictionary into memory using a package called pickle. The keys in this dictionary are country names, and the values are lists containing the following three pieces of information:\n",
    "    \n",
    "<ul>\n",
    "    <li>The two letter abbreviation of the country name</li>\n",
    "    <li>A core civil society index (CCSI) constructed from a number of low-level indicators, including the extent to which major civil society organizations (CSOs) are consulted by policymakers; how large the involvement of people in CSOs is; whether women are prevented from participating; and whether legislative candidate nomination within party organization is highly decentralized or made through party primaries? The index values range from 0 to 1.</li>\n",
    "    <li>A free association index that measures the extent to which parties, including opposition parties, allowed to form and to participate in elections, and the extent to which civil society organizations are able to form and to operate freely. Scores range from 0 to 1.</li> \n",
    "</ul>\n",
    "    \n",
    "In the code block below, print the CCSI (Core Civil Society Index) for Brazil (in 2019).  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.713\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('data/country_dicts.pkl', 'rb') as f:\n",
    "    country_data = pickle.load(f)\n",
    "    \n",
    "brazil = country_data['Brazil'][1]\n",
    "print(f'{brazil}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "The cell below accepts the names of two countries, retrieves their CCSI values from the <strong>country_data</strong> dict, and then returns the name and score for the country with the higher value in a formatted string. Use the function to compare Japan and South Korea. Complete the cell. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'South Korea (0.8240000000000001) had the higher CCSI value in 2019.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_countries(country_a, country_b, country_data):\n",
    "    if country_data[country_a][1] > country_data[country_b][1]:\n",
    "        print(f'{country_a} ({country_data[country_a][1]})')\n",
    "    else:\n",
    "        return f'{country_b} ({country_data[country_b][1]}) had the higher CCSI value in 2019.'\n",
    "\n",
    "compare_countries('Japan', 'South Korea', country_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "The cell below defines a function that accepts two country names as arguments, gets their CCSI values (Core Civil Society Index) from our <strong>country_data</strong> dict, and then returns to the difference between the two countries by subtracting the CCSI of the second country from the CCSI of the first. Use the function to compare the CCSI values for Canada and Argentina. Complete the cell.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1469999999999999"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_ccsi(country_a, country_b, country_data):\n",
    "    diff = country_data[country_a][1] - country_data[country_b][1]\n",
    "    return diff\n",
    "\n",
    "\n",
    "compare_ccsi('Canada', 'Argentina', country_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "The cell below defines a function that accepts a list of country names (well, actually any string) as an argument. It iterates over each country in the list and retrieves the three letter country abbreviation from the list of dictionaries we just used. It outputs a list of tuples, where the first element of the tuple is the country name and the second is the abbreviated name. The function uses a bit of <strong>try / except</strong> logic to handle potential errors (e.g. encountering a string that doesn't match any of the keys in the country dictionaries). Complete the cell.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucessfully reorganized: [('Canada', 'CAN'), ('Brazil', 'BRA')]\n",
      "I have never heard of: ['Norway', 'Brazanada']\n"
     ]
    }
   ],
   "source": [
    "def reorganize_data(list_of_countries, country_data):\n",
    "    results = []\n",
    "    problems = []\n",
    "    for country in list_of_countries:\n",
    "        try:\n",
    "            restructured = tuple([country, country_data[country][0]])\n",
    "            results.append(restructured)\n",
    "        except:\n",
    "            problems.append(country)\n",
    "            \n",
    "    return results, problems\n",
    "\n",
    "\n",
    "reorganized, problems = reorganize_data(['Canada', 'Brazil', 'Norway', 'Brazanada'], country_data)\n",
    "print(f'Sucessfully reorganized: {[country for country in reorganized]}')\n",
    "print(f'I have never heard of: {[country for country in problems]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 3\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    The file <strong>sanders_oped.txt</strong> contains the text of an op-ed that Bernie Sanders published in <em>The Guardian</em> on Wednesday January 20th, 2021, the day that Joe Biden and Kamala Harris were sworn in as President and Vice-President of the United States. The code cell below reads in the text file, strips out line breaks ('\\n'), and ignores lines that don't contain any text. Complete the missing code in the function <strong>get_sentences()</strong>, which attempts to convert the lists of paragraphs to a list of individual sentences by splitting on periods.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www',\n",
       " 'theguardian',\n",
       " 'com/commentisfree/2021/jan/20/joe-biden-action-bernie-sanders',\n",
       " 'Joe Biden must put an end to business as usual',\n",
       " \"Here's where to start | Bernie Sanders\",\n",
       " 'Bernie Sanders Wed 20 Jan 2021 11',\n",
       " '16 GMT',\n",
       " 'In this time of unprecedented crises, Congress and the Biden administration must respond through unprecedented action',\n",
       " 'A record-breaking 4,000 Americans are now dying each day from Covid-19, while the federal government fumbles vaccine production and distribution, testing and tracing',\n",
       " 'In the midst of the worst pandemic in 100 years, more than 90 million Americans are uninsured or underinsured and can’t afford to go to a doctor when they get sick',\n",
       " 'The isolation and anxiety caused by the pandemic has resulted in a huge increase in mental illness',\n",
       " 'Over half of American workers are living paycheck to paycheck, including millions of essential workers who put their lives on the line every day',\n",
       " 'More than 24 million Americans are unemployed, underemployed or have given up looking for work, while hunger in this country is at the highest level in decades',\n",
       " 'Because of lack of income, up to 40 million Americans face the threat of eviction, and many owe thousands in back rent',\n",
       " 'This is on top of the 500,000 who are already homeless',\n",
       " 'Meanwhile, the wealthiest people in this country are becoming much richer, and income and wealth inequality are soaring',\n",
       " 'Incredibly, during the pandemic, 650 billionaires in America have increased their wealth by more than $1tn',\n",
       " 'As a result of the pandemic education in this country, from childcare to graduate school, is in chaos',\n",
       " 'The majority of young people in this country have seen their education disrupted and it is likely that hundreds of colleges will soon cease to exist',\n",
       " 'Climate change is ravaging the planet with an unprecedented number of forest fires and extreme weather disturbances',\n",
       " 'Scientists tell us that we have only a very few years before irreparable damage takes place to our country and the world',\n",
       " 'And, in the midst of all this, the foundations of American democracy are under an unprecedented attack',\n",
       " 'We have a president who is working feverishly to undermine American democracy and incite violence against the very government and constitution he swore to defend',\n",
       " 'Against all of the evidence, tens of millions of Americans actually believe Trump’s Big Lie that he won this election by a landslide and that victory was stolen from him and his supporters',\n",
       " 'Armed rightwing militias in support of Trump are being mobilized throughout the country',\n",
       " 'In this moment of unprecedented crises, Congress and the Biden administration must respond through unprecedented action',\n",
       " 'No more business as usual',\n",
       " 'No more same old, same old',\n",
       " 'Democrats, who will now control the White House, the Senate and the House, must summon the courage to demonstrate to the American people that government can effectively and rapidly respond to their pain and anxiety',\n",
       " 'As the incoming chairman of the Senate budget committee that is exactly what I intend to do',\n",
       " 'What does all of this mean for the average American?',\n",
       " 'It means that we aggressively crush the pandemic and enable the American people to return to their jobs and schools',\n",
       " 'This will require a federally led emergency program to produce the quantity of vaccines that we need and get them into people’s arms as quickly as possible',\n",
       " 'It means that during the severe economic downturn we’re experiencing, we must make sure that all Americans have the financial resources they need to live with dignity',\n",
       " 'We must increase the $600 in direct payments for every working-class adult and child that was recently passed to $2,000, raise the minimum wage to $15 an hour, expand unemployment benefits and prevent eviction, homelessness and hunger',\n",
       " 'Despite what you may have heard, there is no reason why we cannot do all of these things',\n",
       " 'It means that, during this raging pandemic, we must guarantee healthcare to all',\n",
       " 'We must also end the international embarrassment of the United States being the only major country on Earth not to provide paid family and medical leave to workers',\n",
       " 'It means making pre-kindergarten and childcare universal and available to every family in America',\n",
       " 'Despite what you may have heard, there is no reason why we cannot do all of these things',\n",
       " 'Through budget reconciliation, a process that only requires a majority vote in the Senate, we can act quickly and pass this emergency legislation',\n",
       " 'But that is not enough',\n",
       " 'This year we must also pass a second reconciliation bill that deals with the major structural changes that our country desperately needs',\n",
       " 'Ultimately, we must confront the grotesque level of income and wealth inequality and create a country that works for all and not just the few',\n",
       " 'Americans should no longer be denied basic economic rights that are guaranteed to people in virtually every other major country',\n",
       " 'This means using a second reconciliation bill to create millions of good-paying jobs rebuilding our crumbling infrastructure and constructing affordable housing, modernizing our schools, combatting climate change and making massive investments in energy efficiency and renewable energy',\n",
       " 'It means making public colleges, universities, trade schools and Historically Black Colleges and Universities tuition-free and forcefully addressing the outrageous level of student debt for working families',\n",
       " 'And it means making the wealthiest Americans and most profitable corporations pay their fair share of taxes',\n",
       " 'We cannot continue to allow profitable corporations like Amazon to make billions of dollars in taxes and pay nothing in net federal income taxes',\n",
       " 'And billionaires cannot be allowed to pay a lower tax rate than working-class Americans',\n",
       " 'We need real tax reform',\n",
       " 'There is no reason Joe Biden could not sign into law two major bills that will accomplish most of the goals I listed above within the first 100 days of the new Congress',\n",
       " 'We cannot allow Mitch McConnell and the Republican leadership to sabotage legislation that would improve the lives of millions of working Americans and is wildly popular',\n",
       " 'Let us never forget',\n",
       " 'When Republicans controlled the Senate, they used the reconciliation process to pass trillions of dollars in tax breaks primarily to the top 1% and multinational corporations',\n",
       " 'Further, they were able to confirm three rightwing US supreme court judges over a very short period of time by a simple majority vote',\n",
       " 'If the Republicans could use the reconciliation process to protect the wealthy and the powerful, we can use it to protect working families, the sick, the elderly, the disabled and the poor',\n",
       " 'Bernie Sanders is a US Senator from Vermont']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/sanders_oped.txt', 'r', encoding='utf-8') as file:\n",
    "    oped = [line.strip('\\n') for line in file if len(line) > 1]\n",
    "\n",
    "\n",
    "def get_sentences(text):\n",
    "    results = []\n",
    "    for paragraph in text:\n",
    "        sentences = paragraph.split('.')\n",
    "        for sentence in sentences:\n",
    "            if len(sentence) > 1:\n",
    "                # Add strip to eliminate leading/trailing spaces\n",
    "                results.append(sentence.strip())\n",
    "    return results\n",
    "\n",
    "\n",
    "sentences = get_sentences(oped)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Complete the function below, which will accept a list of strings and return a new list containing the length of each string (i.e. the number of words in the string). Count the number of words in each sentence of Sander's oped by passing the <strong>oped</strong> list of strings to your new function and then confirm that the list of numbers and the list of strings are the same length.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[85, 86, 40, 117, 431, 306, 175, 228, 252, 238, 545, 175, 308, 52, 273, 403, 88, 245, 98, 236, 433, 286, 207, 368, 340, 331, 189, 43]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def senlens(string_list):\n",
    "    lens = [len(sen) for sen in string_list]\n",
    "    return lens\n",
    "\n",
    "oped_sentence_lens = senlens(oped)\n",
    "print(oped_sentence_lens)\n",
    "\n",
    "len(oped_sentence_lens) == len(oped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "The cell below contains a for loop that iterates over the sentences in Sander's oped and creates two new lists: one for sentences that contain the word \"Republican,\" the other for sentences that contain the word \"Democrat.\" Complete the code and then print the lengths of each.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 sentence contains the word Democrat and 3 sentences contain the word Republican.\n"
     ]
    }
   ],
   "source": [
    "democrat = []\n",
    "republican = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    if \"Democrat\" in sentence:\n",
    "        democrat.append(sentence)\n",
    "    if \"Republican\" in sentence:\n",
    "        republican.append(sentence)\n",
    "        \n",
    "print(f'{len(democrat)} sentence contains the word Democrat and {len(republican)} sentences contain the word Republican.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "The cell below iterates over the sentences in Sanders' oped and prints the sentence to screen if it contains a word of interest. Pick a word that you know (or suspect) is in the oped (Biden, Trump, polarization, etc.) and assign it to the string object \"search.\" Then complete the rest of the code cell to print any sentence that contains that word.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A record-breaking 4,000 Americans are now dying each day from Covid-19, while the federal government fumbles vaccine production and distribution, testing and tracing\n",
      "In the midst of the worst pandemic in 100 years, more than 90 million Americans are uninsured or underinsured and can’t afford to go to a doctor when they get sick\n",
      "More than 24 million Americans are unemployed, underemployed or have given up looking for work, while hunger in this country is at the highest level in decades\n",
      "Because of lack of income, up to 40 million Americans face the threat of eviction, and many owe thousands in back rent\n",
      "Against all of the evidence, tens of millions of Americans actually believe Trump’s Big Lie that he won this election by a landslide and that victory was stolen from him and his supporters\n",
      "It means that during the severe economic downturn we’re experiencing, we must make sure that all Americans have the financial resources they need to live with dignity\n",
      "Americans should no longer be denied basic economic rights that are guaranteed to people in virtually every other major country\n",
      "And it means making the wealthiest Americans and most profitable corporations pay their fair share of taxes\n",
      "And billionaires cannot be allowed to pay a lower tax rate than working-class Americans\n",
      "We cannot allow Mitch McConnell and the Republican leadership to sabotage legislation that would improve the lives of millions of working Americans and is wildly popular\n"
     ]
    }
   ],
   "source": [
    "search = 'Americans'\n",
    "\n",
    "for sentence in sentences:\n",
    "    if search in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 4\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Create a new text file using Jupyter (<strong>here's how to do that</strong>) or your preferred text editor that contains the names of 5-10 podcasts you listen to, books you've recently read, musical genres you prefer, or TV shows you've recently watched. When you are entering the information into the text file, put the name of each podcast, book, genre, or TV show on a new line. Save the text file in the same directory that your notebook is in. Once you've done that, use the cell below to read that text file into Python as a list. Each seperete item (e.g. book, podcast episode, whatever) is a different item in the list. Print the list contents as well as the index position of each item in the list using <strong>enumerate()</strong>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Succession\n",
      "1 Westworld\n",
      "2 The Mandalorian\n",
      "3 Hunter x Hunter\n",
      "4 Attack on Titan\n"
     ]
    }
   ],
   "source": [
    "with open('tv_shows.txt', 'r', encoding='utf-8') as shows:\n",
    "    likes = [show.split('\\n')[0] for show in shows]\n",
    "\n",
    "for i,l in enumerate(likes):\n",
    "    print(i,l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Complete the code below so that the sentence prints to screen properly for each item in your list of likes.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, you were into Succession before it was cool to be into Succession?\n",
      "Oh, you were into Westworld before it was cool to be into Westworld?\n",
      "Oh, you were into The Mandalorian before it was cool to be into The Mandalorian?\n",
      "Oh, you were into Hunter x Hunter before it was cool to be into Hunter x Hunter?\n",
      "Oh, you were into Attack on Titan before it was cool to be into Attack on Titan?\n"
     ]
    }
   ],
   "source": [
    "for like in likes:\n",
    "    print(f'Oh, you were into {like} before it was cool to be into {like}?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Complete the function below to search your list of likes for some specific item, and then print a formatted string depending on whether that item is in your list of likes.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, I love The Mandalorian!\n",
      "Hmm, sorry I've never heard of Lupin before. Anyway, what do you think of Frank Ocean?\n"
     ]
    }
   ],
   "source": [
    "def do_you_like(item, list_of_likes):\n",
    "    if item in list_of_likes:\n",
    "        print(f'Yes, I love {item}!')\n",
    "    else:\n",
    "        print(f\"Hmm, sorry I've never heard of {item} before. Anyway, what do you think of Frank Ocean?\")\n",
    "        \n",
    "        \n",
    "what_1 = 'The Mandalorian' # something in your list\n",
    "do_you_like(what_1, likes)\n",
    "\n",
    "what_2 = 'Lupin' # something not in your list\n",
    "do_you_like(what_2, likes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Enter 6 more things you like into the list <strong>more_things_i_like</strong>. Make sure that exactly 2 of those things were also listed in your initial list of likes. Complete the code in the cell below to combine the two lists, obtain a list of unique items by converting the combined list to a <strong>set</strong> and print the results to screen.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a list of 9 things I really like:\n",
      "\n",
      "- Atlanta\n",
      "- Attack on Titan\n",
      "- Euphoria\n",
      "- Hunter x Hunter\n",
      "- Maniac\n",
      "- Silicon Valley\n",
      "- Succession\n",
      "- The Mandalorian\n",
      "- Westworld\n"
     ]
    }
   ],
   "source": [
    "more_things_i_like = ['Euphoria', 'Atlanta', 'Silicon Valley', 'Maniac', 'Succession', 'Westworld']\n",
    "\n",
    "def get_unique_items(list1, list2):\n",
    "    all_likes = list1 + list2\n",
    "    unique_likes = set(all_likes)\n",
    "    return unique_likes\n",
    "\n",
    "unique_likes = get_unique_items(likes, more_things_i_like)\n",
    "\n",
    "print(f\"Here's a list of {len(unique_likes)} things I really like:\\n\")\n",
    "for like in sorted(unique_likes):\n",
    "    print(f'- {like}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h1><font size=40>Submit your feedback!</font></h1>\n",
    "</div>\n",
    "\n",
    "I would very much appreciate your constructive feedback on how to improve the assigned reading and notebook assignment **for this module**. In the cells below, please let us know \n",
    "\n",
    "1. what worked for you, and\n",
    "2. what didn't work for you.\n",
    "\n",
    "Remember, I am willing to offer **up to 5% bonus marks on your final course grade** for feedback offered consistently over the course of the semester that improves the quality of the book *Doing Computational Social Science* or this course. Help us make this course the best we can for future students!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <strong>Feedback on the assigned chapters from <em>Doing Computational Social Science</em></strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Double click me)**    \n",
    "Type your feedback here! Thanks. :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <strong>Feedback on this module notebook assignment.</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Double click me)**    \n",
    "Type your feedback here! Thanks. :) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
